{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sam80FDS/Sam/blob/main/AI_Shorts_Server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f95557ce",
      "metadata": {
        "id": "f95557ce"
      },
      "source": [
        "# Zero-Cost YouTube Shorts Factory - AI Rendering Server\n",
        "\n",
        "This notebook runs on **Google Colab Free Tier** and provides a FastAPI server for rendering viral tech news shorts.\n",
        "\n",
        "**Architecture:**\n",
        "- Edge-TTS for voice generation (free, unrestricted)\n",
        "- EchoMimic/SadTalker for avatar animation\n",
        "- FFmpeg for audio mixing and compositing\n",
        "- ngrok for public HTTPS tunnel to n8n\n",
        "- Google Drive for storage\n",
        "\n",
        "**Cost: $0 (100% free tier)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1328f48",
      "metadata": {
        "id": "d1328f48"
      },
      "source": [
        "## Section 1: Setup and Dependencies\n",
        "\n",
        "Install all required packages for audio/video processing, API server, and Drive integration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29d12a9a",
      "metadata": {
        "id": "29d12a9a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Install system dependencies\n",
        "print(\"Installing system dependencies...\")\n",
        "subprocess.run(['apt-get', 'update'], check=True, capture_output=True)\n",
        "subprocess.run(['apt-get', 'install', '-y', 'ffmpeg', 'libsm6', 'libxext6'],\n",
        "               check=True, capture_output=True)\n",
        "\n",
        "# Install Python packages\n",
        "packages = [\n",
        "    'fastapi',\n",
        "    'uvicorn',\n",
        "    'pyngrok',\n",
        "    'nest_asyncio',\n",
        "    'edge-tts',\n",
        "    'opencv-python',\n",
        "    'scipy',\n",
        "    'requests',\n",
        "    'python-multipart',\n",
        "    'aiofiles'\n",
        "]\n",
        "\n",
        "print(\"Installing Python packages...\")\n",
        "for package in packages:\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', package],\n",
        "                   check=True, capture_output=True)\n",
        "\n",
        "print(\"âœ“ All dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acaf0ba6",
      "metadata": {
        "id": "acaf0ba6"
      },
      "source": [
        "## Section 2: Google Drive Integration and Asset Paths\n",
        "\n",
        "Mount Google Drive and validate the folder structure for music and output directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8e3ea2f",
      "metadata": {
        "id": "e8e3ea2f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define asset paths\n",
        "DRIVE_BASE = '/content/drive/MyDrive'\n",
        "MUSIC_FOLDER = os.path.join(DRIVE_BASE, 'Shorts_Assets/Music')\n",
        "OUTPUT_FOLDER = os.path.join(DRIVE_BASE, 'Shorts_Output')\n",
        "TEMP_FOLDER = '/content/temp_shorts'\n",
        "\n",
        "# Create necessary directories\n",
        "for folder in [MUSIC_FOLDER, OUTPUT_FOLDER, TEMP_FOLDER]:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    print(f\"âœ“ Folder ready: {folder}\")\n",
        "\n",
        "# Validate music folder has content\n",
        "music_files = [f for f in os.listdir(MUSIC_FOLDER) if f.endswith(('.mp3', '.wav', '.m4a'))]\n",
        "print(f\"\\nâœ“ Found {len(music_files)} music tracks in Music folder\")\n",
        "if len(music_files) < 3:\n",
        "    print(\"âš ï¸  WARNING: Less than 3 music tracks. Recommendation: Upload 20-30 safe tracks to ensure variety.\")\n",
        "    print(\"   See Section 9 for music sources.\")\n",
        "\n",
        "# Environment variables\n",
        "os.environ['MUSIC_FOLDER'] = MUSIC_FOLDER\n",
        "os.environ['OUTPUT_FOLDER'] = OUTPUT_FOLDER\n",
        "os.environ['TEMP_FOLDER'] = TEMP_FOLDER\n",
        "print(\"\\nâœ“ Environment variables configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30268577",
      "metadata": {
        "id": "30268577"
      },
      "source": [
        "## Section 3: Edge-TTS Voice Generation\n",
        "\n",
        "Generate speech audio from script text using Edge-TTS with viral-optimized voices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97d8e0ad",
      "metadata": {
        "id": "97d8e0ad"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import edge_tts\n",
        "from scipy.io import wavfile\n",
        "import wave\n",
        "import struct\n",
        "\n",
        "async def generate_voice_audio(script_text: str, voice: str = \"en-US-ChristopherNeural\",\n",
        "                               output_path: str = None) -> tuple:\n",
        "    \"\"\"\n",
        "    Generate speech audio from script text using Edge-TTS.\n",
        "\n",
        "    Args:\n",
        "        script_text: The script to convert to speech\n",
        "        voice: Voice ID (ChristopherNeural, GuyNeural, AriaNeural recommended)\n",
        "        output_path: Where to save the audio file\n",
        "\n",
        "    Returns:\n",
        "        (audio_file_path, duration_seconds)\n",
        "    \"\"\"\n",
        "    if output_path is None:\n",
        "        output_path = os.path.join(os.environ['TEMP_FOLDER'], 'voice_output.mp3')\n",
        "\n",
        "    # Create communicate object\n",
        "    communicate = edge_tts.Communicate(script_text, voice, rate=\"+0%\", volume=\"+0%\")\n",
        "\n",
        "    # Save audio file\n",
        "    await communicate.save(output_path)\n",
        "\n",
        "    # Get duration using ffprobe\n",
        "    result = subprocess.run(\n",
        "        ['ffprobe', '-v', 'error', '-show_entries', 'format=duration',\n",
        "         '-of', 'default=noprint_wrappers=1:nokey=1:nokey=1', output_path],\n",
        "        capture_output=True, text=True\n",
        "    )\n",
        "\n",
        "    duration = float(result.stdout.strip())\n",
        "\n",
        "    print(f\"âœ“ Voice generated: {duration:.2f} seconds\")\n",
        "    return output_path, duration\n",
        "\n",
        "# Test voice generation\n",
        "async def test_voice():\n",
        "    test_script = \"This changes everything. Artificial intelligence just got upgraded. Your tools are about to feel obsolete.\"\n",
        "    voice_file, duration = await generate_voice_audio(test_script)\n",
        "    print(f\"âœ“ Test voice file: {voice_file}\")\n",
        "    print(f\"âœ“ Duration: {duration:.2f}s\")\n",
        "    return voice_file, duration\n",
        "\n",
        "# Run test\n",
        "asyncio.run(test_voice())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5186a5f8",
      "metadata": {
        "id": "5186a5f8"
      },
      "source": [
        "## Section 4: FFmpeg Audio Mixing with Auto-Ducking\n",
        "\n",
        "Mix voice audio with background music using FFmpeg, with automatic volume ducking to prevent masking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16be19a6",
      "metadata": {
        "id": "16be19a6"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def select_random_music(music_folder: str = None) -> str:\n",
        "    \"\"\"Randomly select one music file from the Music folder.\"\"\"\n",
        "    if music_folder is None:\n",
        "        music_folder = os.environ['MUSIC_FOLDER']\n",
        "\n",
        "    music_files = [f for f in os.listdir(music_folder)\n",
        "                   if f.endswith(('.mp3', '.wav', '.m4a', '.aac'))]\n",
        "\n",
        "    if not music_files:\n",
        "        raise FileNotFoundError(f\"No music files found in {music_folder}\")\n",
        "\n",
        "    selected = random.choice(music_files)\n",
        "    full_path = os.path.join(music_folder, selected)\n",
        "    print(f\"âœ“ Selected music: {selected}\")\n",
        "    return full_path\n",
        "\n",
        "def mix_audio_with_auto_ducking(voice_file: str, voice_duration: float,\n",
        "                                 output_audio: str = None,\n",
        "                                 music_volume: float = 0.1) -> str:\n",
        "    \"\"\"\n",
        "    Mix voice audio with background music using FFmpeg.\n",
        "    Auto-ducking: Music volume is reduced to 10% so voice is always clear.\n",
        "\n",
        "    Args:\n",
        "        voice_file: Path to voice MP3/WAV\n",
        "        voice_duration: Duration of voice in seconds\n",
        "        output_audio: Output audio file path\n",
        "        music_volume: Volume level for music (0.0-1.0, default 0.1 = 10%)\n",
        "\n",
        "    Returns:\n",
        "        Path to mixed audio file\n",
        "    \"\"\"\n",
        "    if output_audio is None:\n",
        "        output_audio = os.path.join(os.environ['TEMP_FOLDER'], 'mixed_audio.wav')\n",
        "\n",
        "    # Select random music\n",
        "    music_file = select_random_music()\n",
        "\n",
        "    # Create FFmpeg command with auto-ducking\n",
        "    ffmpeg_cmd = [\n",
        "        'ffmpeg', '-y',\n",
        "        '-i', voice_file,\n",
        "        '-i', music_file,\n",
        "        '-filter_complex',\n",
        "        f'[1]volume={music_volume}[mus];[0][mus]amix=inputs=2:duration=first[out]',\n",
        "        '-map', '[out]',\n",
        "        '-t', str(voice_duration),  # Trim to voice duration\n",
        "        '-c:a', 'pcm_s16le',  # WAV codec\n",
        "        '-ar', '44100',  # 44.1kHz sample rate\n",
        "        output_audio\n",
        "    ]\n",
        "\n",
        "    print(f\"Mixing audio (voice + {music_volume*100:.0f}% music)...\")\n",
        "    result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)\n",
        "\n",
        "    if result.returncode != 0:\n",
        "        print(f\"FFmpeg Error: {result.stderr}\")\n",
        "        raise RuntimeError(\"FFmpeg audio mixing failed\")\n",
        "\n",
        "    print(f\"âœ“ Audio mixed: {output_audio}\")\n",
        "    return output_audio\n",
        "\n",
        "# Test audio mixing\n",
        "voice_file, voice_duration = asyncio.run(test_voice())\n",
        "mixed_audio = mix_audio_with_auto_ducking(voice_file, voice_duration)\n",
        "print(f\"âœ“ Test complete: {mixed_audio}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82d758ed",
      "metadata": {
        "id": "82d758ed"
      },
      "source": [
        "## Section 5: Avatar Animation with EchoMimic/SadTalker\n",
        "\n",
        "Generate animated avatar video from audio using EchoMimic (recommended for free tier).\n",
        "\n",
        "**Note:** For zero-cost, we use a simplified approach with a static avatar + subtle movement animation. For production quality, integrate EchoMimic properly after cloning the repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a5aa943",
      "metadata": {
        "id": "8a5aa943"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def create_placeholder_animated_avatar(duration: float, width: int = 512, height: int = 512,\n",
        "                                       output_path: str = None) -> str:\n",
        "    \"\"\"\n",
        "    Create a placeholder animated avatar video.\n",
        "\n",
        "    PRODUCTION NOTE: Replace this with actual EchoMimic integration:\n",
        "    1. Clone: git clone https://github.com/BadToBest/EchoMimic.git\n",
        "    2. Use EchoMimic to animate real avatar with audio\n",
        "    3. This placeholder generates subtle animations for testing\n",
        "\n",
        "    Args:\n",
        "        duration: Video duration in seconds\n",
        "        width, height: Video dimensions\n",
        "        output_path: Output video path\n",
        "\n",
        "    Returns:\n",
        "        Path to avatar video file\n",
        "    \"\"\"\n",
        "    if output_path is None:\n",
        "        output_path = os.path.join(os.environ['TEMP_FOLDER'], 'avatar.mp4')\n",
        "\n",
        "    # Video properties\n",
        "    fps = 30\n",
        "    total_frames = int(duration * fps)\n",
        "\n",
        "    # Initialize video writer\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    print(f\"Creating placeholder avatar video: {total_frames} frames at {fps} fps...\")\n",
        "\n",
        "    # Create frames with subtle animation\n",
        "    for frame_idx in range(total_frames):\n",
        "        # Create a frame with gradient background (simulating avatar face)\n",
        "        frame = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "\n",
        "        # Gradient background (dark blue to cyan)\n",
        "        for y in range(height):\n",
        "            frame[y, :] = [int(100 + y * 0.05), int(150 + y * 0.02), 200]\n",
        "\n",
        "        # Draw animated circle (simulating breathing/blinking)\n",
        "        center_x, center_y = width // 2, height // 2\n",
        "        radius = 80 + int(10 * np.sin(frame_idx * 0.1))  # Breathing animation\n",
        "\n",
        "        cv2.circle(frame, (center_x, center_y), radius, (255, 200, 100), -1)\n",
        "\n",
        "        # Add subtle eye animation\n",
        "        eye_y_offset = int(5 * np.sin(frame_idx * 0.15))\n",
        "        cv2.circle(frame, (center_x - 25, center_y - 20 + eye_y_offset), 8, (0, 0, 0), -1)\n",
        "        cv2.circle(frame, (center_x + 25, center_y - 20 + eye_y_offset), 8, (0, 0, 0), -1)\n",
        "\n",
        "        # Write frame\n",
        "        out.write(frame)\n",
        "\n",
        "        if (frame_idx + 1) % (fps * 10) == 0:\n",
        "            print(f\"  Generated {frame_idx + 1}/{total_frames} frames...\")\n",
        "\n",
        "    out.release()\n",
        "    print(f\"âœ“ Avatar video created: {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "# Test avatar generation\n",
        "test_avatar = create_placeholder_animated_avatar(5.0)\n",
        "print(f\"âœ“ Test avatar: {test_avatar}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "357a00d4",
      "metadata": {
        "id": "357a00d4"
      },
      "source": [
        "## Section 6: Video Compositing and Rendering\n",
        "\n",
        "Compose the animated avatar onto a background image and generate the final video with audio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "880e4449",
      "metadata": {
        "id": "880e4449"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "from PIL import Image\n",
        "\n",
        "def download_and_prepare_background(image_url: str, width: int = 1080, height: int = 1920) -> str:\n",
        "    \"\"\"\n",
        "    Download background image from URL and resize for 9:16 vertical format.\n",
        "\n",
        "    Args:\n",
        "        image_url: URL of background image\n",
        "        width: Output width (default 1080 for YouTube Shorts)\n",
        "        height: Output height (default 1920 for 9:16 aspect ratio)\n",
        "\n",
        "    Returns:\n",
        "        Path to resized background image\n",
        "    \"\"\"\n",
        "    bg_path = os.path.join(os.environ['TEMP_FOLDER'], 'background.jpg')\n",
        "\n",
        "    print(f\"Downloading background image from {image_url}...\")\n",
        "    urllib.request.urlretrieve(image_url, bg_path)\n",
        "\n",
        "    # Open and resize\n",
        "    img = Image.open(bg_path)\n",
        "    img = img.resize((width, height), Image.Resampling.LANCZOS)\n",
        "    img.save(bg_path)\n",
        "\n",
        "    print(f\"âœ“ Background prepared: {width}x{height}\")\n",
        "    return bg_path\n",
        "\n",
        "def composite_avatar_on_background(avatar_video: str, background_image: str,\n",
        "                                    audio_file: str, output_video: str = None,\n",
        "                                    avatar_scale: float = 0.5, avatar_x_pos: float = 0.5) -> str:\n",
        "    \"\"\"\n",
        "    Composite animated avatar onto background and add audio.\n",
        "\n",
        "    Args:\n",
        "        avatar_video: Path to avatar animation video\n",
        "        background_image: Path to background image\n",
        "        audio_file: Path to mixed audio (voice + music)\n",
        "        output_video: Output video path\n",
        "        avatar_scale: Scale of avatar relative to frame (0-1)\n",
        "        avatar_x_pos: Horizontal position (0=left, 0.5=center, 1=right)\n",
        "\n",
        "    Returns:\n",
        "        Path to final composited video\n",
        "    \"\"\"\n",
        "    if output_video is None:\n",
        "        output_video = os.path.join(os.environ['TEMP_FOLDER'], 'final_composite.mp4')\n",
        "\n",
        "    print(\"Compositing avatar onto background...\")\n",
        "\n",
        "    # FFmpeg filter: Overlay avatar at 50% size, centered\n",
        "    filter_complex = (\n",
        "        f\"[0]scale=540:960[avatar];\"  # Scale avatar to 50% (1080x1920 -> 540x960)\n",
        "        f\"[1][avatar]overlay=(main_w-overlay_w)/2:(main_h-overlay_h)/2[bg];\"  # Center overlay\n",
        "        f\"[bg]pad=width=1080:height=1920:x=0:y=0[final]\"  # Ensure 1080x1920\n",
        "    )\n",
        "\n",
        "    ffmpeg_cmd = [\n",
        "        'ffmpeg', '-y',\n",
        "        '-loop', '1', '-i', background_image,\n",
        "        '-i', avatar_video,\n",
        "        '-i', audio_file,\n",
        "        '-filter_complex', filter_complex,\n",
        "        '-map', '[final]',\n",
        "        '-map', '2:a',\n",
        "        '-c:v', 'libx264',\n",
        "        '-preset', 'fast',  # Fast for Colab\n",
        "        '-c:a', 'aac',\n",
        "        '-shortest',  # Stop when audio ends\n",
        "        output_video\n",
        "    ]\n",
        "\n",
        "    result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)\n",
        "\n",
        "    if result.returncode != 0:\n",
        "        print(f\"FFmpeg Error: {result.stderr}\")\n",
        "        raise RuntimeError(\"FFmpeg compositing failed\")\n",
        "\n",
        "    # Get video size\n",
        "    size_result = subprocess.run(\n",
        "        ['ffprobe', '-v', 'error', '-show_entries', 'stream=width,height',\n",
        "         '-of', 'csv=p=0', output_video],\n",
        "        capture_output=True, text=True\n",
        "    )\n",
        "    print(f\"âœ“ Final video created: {output_video}\")\n",
        "    print(f\"  Resolution: {size_result.stdout.strip()}\")\n",
        "\n",
        "    return output_video\n",
        "\n",
        "# Note: To test compositing, we'd need a background image URL\n",
        "# Example: background = download_and_prepare_background(\"https://example.com/news-bg.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2397e6eb",
      "metadata": {
        "id": "2397e6eb"
      },
      "source": [
        "## Section 7: FastAPI Endpoint for /render-short\n",
        "\n",
        "Create the FastAPI server with the `/render-short` endpoint for orchestrating the entire rendering pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb3b715d",
      "metadata": {
        "id": "cb3b715d"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "import json\n",
        "from datetime import datetime\n",
        "import nest_asyncio\n",
        "\n",
        "# Enable nested asyncio for Jupyter\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Initialize FastAPI\n",
        "app = FastAPI(title=\"YouTube Shorts Rendering Server\", version=\"1.0.0\")\n",
        "\n",
        "# Request model\n",
        "class RenderRequest(BaseModel):\n",
        "    script_text: str\n",
        "    background_image_url: str\n",
        "    voice: str = \"en-US-ChristopherNeural\"  # Default viral voice\n",
        "    project_id: str = None  # Optional identifier for tracking\n",
        "\n",
        "@app.get(\"/health\")\n",
        "async def health_check():\n",
        "    \"\"\"Health check endpoint for n8n webhook monitoring.\"\"\"\n",
        "    return {\n",
        "        \"status\": \"healthy\",\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"service\": \"YouTube Shorts Rendering Server\"\n",
        "    }\n",
        "\n",
        "@app.post(\"/render-short\")\n",
        "async def render_short(request: RenderRequest):\n",
        "    \"\"\"\n",
        "    Main rendering endpoint.\n",
        "\n",
        "    Orchestrates: Voice Generation -> Avatar Animation -> Audio Mixing -> Compositing\n",
        "\n",
        "    Args:\n",
        "        request: RenderRequest with script_text and background_image_url\n",
        "\n",
        "    Returns:\n",
        "        {\n",
        "            \"status\": \"success\",\n",
        "            \"video_path\": \"path/to/final/video.mp4\",\n",
        "            \"duration_seconds\": 50,\n",
        "            \"project_id\": \"xyz123\"\n",
        "        }\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Starting render: {request.project_id or 'unnamed'}\")\n",
        "        print(f\"Script length: {len(request.script_text)} chars\")\n",
        "        print(f\"Voice: {request.voice}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Step 1: Generate voice audio\n",
        "        print(\"\\n[STEP 1/4] Generating voice audio...\")\n",
        "        voice_file, voice_duration = await generate_voice_audio(\n",
        "            request.script_text,\n",
        "            voice=request.voice\n",
        "        )\n",
        "\n",
        "        # Step 2: Create avatar animation\n",
        "        print(\"\\n[STEP 2/4] Creating avatar animation...\")\n",
        "        avatar_video = create_placeholder_animated_avatar(voice_duration)\n",
        "        # FUTURE: Replace with EchoMimic integration\n",
        "\n",
        "        # Step 3: Mix audio (voice + music with auto-ducking)\n",
        "        print(\"\\n[STEP 3/4] Mixing audio (voice + background music at 10%)...\")\n",
        "        mixed_audio = mix_audio_with_auto_ducking(voice_file, voice_duration)\n",
        "\n",
        "        # Step 4a: Download and prepare background\n",
        "        print(\"\\n[STEP 4a/4] Downloading background image...\")\n",
        "        background_image = download_and_prepare_background(request.background_image_url)\n",
        "\n",
        "        # Step 4b: Composite and render final video\n",
        "        print(\"\\n[STEP 4b/4] Compositing final video...\")\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        final_video = os.path.join(\n",
        "            os.environ['OUTPUT_FOLDER'],\n",
        "            f\"short_{request.project_id or timestamp}.mp4\"\n",
        "        )\n",
        "\n",
        "        final_video = composite_avatar_on_background(\n",
        "            avatar_video,\n",
        "            background_image,\n",
        "            mixed_audio,\n",
        "            final_video\n",
        "        )\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"âœ“ RENDER COMPLETE\")\n",
        "        print(f\"  Video: {final_video}\")\n",
        "        print(f\"  Duration: {voice_duration:.2f}s\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "        return {\n",
        "            \"status\": \"success\",\n",
        "            \"video_path\": final_video,\n",
        "            \"duration_seconds\": voice_duration,\n",
        "            \"project_id\": request.project_id or timestamp,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: {str(e)}\")\n",
        "        raise HTTPException(\n",
        "            status_code=500,\n",
        "            detail=f\"Rendering failed: {str(e)}\"\n",
        "        )\n",
        "\n",
        "print(\"âœ“ FastAPI app configured with /health and /render-short endpoints\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65d76d74",
      "metadata": {
        "id": "65d76d74"
      },
      "source": [
        "## Section 8: ngrok Tunneling for n8n Webhooks\n",
        "\n",
        "Launch the FastAPI server with ngrok to create a public HTTPS URL for n8n HTTP requests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dafe251f",
      "metadata": {
        "id": "dafe251f"
      },
      "outputs": [],
      "source": [
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# Configure ngrok (free tier)\n",
        "# ngrok.set_auth_token(\"YOUR_NGROK_AUTH_TOKEN\")  # Optional: For persistent URLs\n",
        "\n",
        "def run_fastapi_server():\n",
        "    \"\"\"Run FastAPI server in a background thread.\"\"\"\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "\n",
        "def start_server_with_ngrok(port: int = 8000, ngrok_auth_token: str = None) -> str:\n",
        "    \"\"\"\n",
        "    Start FastAPI server and create ngrok tunnel.\n",
        "\n",
        "    Args:\n",
        "        port: Port to run FastAPI on\n",
        "        ngrok_auth_token: Optional ngrok auth token for persistent URLs\n",
        "\n",
        "    Returns:\n",
        "        Public HTTPS URL for n8n to call\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Starting YouTube Shorts Rendering Server\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Set auth token if provided\n",
        "    if ngrok_auth_token:\n",
        "        ngrok.set_auth_token(ngrok_auth_token)\n",
        "\n",
        "    # Start FastAPI in background thread\n",
        "    server_thread = threading.Thread(target=run_fastapi_server, daemon=True)\n",
        "    server_thread.start()\n",
        "\n",
        "    print(f\"âœ“ FastAPI server starting on port {port}...\")\n",
        "    time.sleep(2)  # Wait for server to start\n",
        "\n",
        "    # Start ngrok tunnel\n",
        "    try:\n",
        "        public_url = ngrok.connect(port, \"http\")\n",
        "        print(f\"\\nâœ“ ngrok tunnel established!\")\n",
        "        print(f\"\\n  PUBLIC NGROK URL: {public_url}\")\n",
        "        print(f\"\\n  Use this URL in n8n HTTP Request nodes:\")\n",
        "        print(f\"  POST {public_url}/render-short\")\n",
        "        print(f\"  POST {public_url}/health\")\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "        return str(public_url)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Failed to create ngrok tunnel: {e}\")\n",
        "        print(\"Make sure ngrok is installed: pip install pyngrok\")\n",
        "        raise\n",
        "\n",
        "# Launch the server\n",
        "try:\n",
        "    # Option 1: Without authentication (free tier, temporary URL)\n",
        "    public_url = start_server_with_ngrok()\n",
        "\n",
        "    # Save URL for reference\n",
        "    with open(os.path.join(os.environ['TEMP_FOLDER'], 'server_url.txt'), 'w') as f:\n",
        "        f.write(f\"ngrok URL: {public_url}\\n\")\n",
        "        f.write(f\"Health Check: {public_url}/health\\n\")\n",
        "        f.write(f\"Render Endpoint: {public_url}/render-short\\n\")\n",
        "\n",
        "    print(\"\\nâœ“ Server URL saved to temp folder\")\n",
        "    print(\"\\nServer is now running and ready for n8n requests!\")\n",
        "    print(\"Keep this notebook cell running to maintain the ngrok tunnel.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Failed to start server: {e}\")\n",
        "    print(\"Troubleshooting: Make sure all dependencies are installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "705e3a75",
      "metadata": {
        "id": "705e3a75"
      },
      "source": [
        "## Section 9: Music Selection and Curation Strategy\n",
        "\n",
        "Complete guide for sourcing copyright-free music for monetization-safe viral shorts."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f312ee8",
      "metadata": {
        "id": "0f312ee8"
      },
      "source": [
        "# Zero-Cost Music Strategy for Viral YouTube Shorts\n",
        "\n",
        "## Why This Matters\n",
        "- **YouTube Monetization:** Any copyrighted music triggers content ID claims (you lose revenue)\n",
        "- **Viral Edge:** Copyright-free â‰  boring. Modern royalty-free has incredible cinematic tracks\n",
        "- **Zero Maintenance:** Upload 20-30 tracks ONCE to Drive, automate forever\n",
        "\n",
        "---\n",
        "\n",
        "## Recommended Free Music Sources\n",
        "\n",
        "### 1. **YouTube Audio Library** (Best Option)\n",
        "- **Cost:** FREE (YouTube account required)\n",
        "- **Quality:** 10,000+ tracks, all monetization-safe\n",
        "- **How to Download:**\n",
        "  1. Go to YouTube Studio â†’ Create â†’ Audio Library\n",
        "  2. Search by mood: \"Inspirational\", \"Upbeat\", \"Cinematic\"\n",
        "  3. Download MP3 to your computer\n",
        "  4. Upload to `/content/drive/MyDrive/Shorts_Assets/Music`\n",
        "- **Best Tracks for Tech News:**\n",
        "  - \"Ukulele Happy\" (upbeat, energetic)\n",
        "  - \"Bright Lights\" (modern, tech-forward)\n",
        "  - \"Inspiring Cinematic\" (authority, credibility)\n",
        "\n",
        "### 2. **Free Music Archive (freemusicarchive.org)**\n",
        "- **Cost:** FREE\n",
        "- **License:** Creative Commons (verify attribution if needed)\n",
        "- **Search Tags:** `upbeat`, `tech`, `electronic`, `energetic`\n",
        "- **Download Tip:** Filter by \"Shortest Duration\" for short-form content (30-60s)\n",
        "\n",
        "### 3. **Epidemic Sound (Free Tier)**\n",
        "- **Cost:** Limited free tier (10 downloads/month)\n",
        "- **Quality:** Studio-grade production\n",
        "- **How to Use:** Download sparingly for critical moments\n",
        "\n",
        "### 4. **CreatorMix (Indian Alternative)**\n",
        "- **Cost:** FREE\n",
        "- **Quality:** Curated Indian royalty-free music\n",
        "- **Best For:** Diverse, energetic tech content\n",
        "- **Website:** creatorix.in (or search \"creatorix free music\")\n",
        "\n",
        "---\n",
        "\n",
        "## Implementation: The \"Mono-Music\" Strategy\n",
        "\n",
        "Instead of complex APIs, do this ONCE:\n",
        "\n",
        "```\n",
        "1. Download 25 tracks from YouTube Audio Library\n",
        "2. Name them: track_001.mp3 â†’ track_025.mp3\n",
        "3. Upload to Google Drive: /MyDrive/Shorts_Assets/Music/\n",
        "4. The system randomly selects one per short\n",
        "5. Run automation forever (0 additional setup needed)\n",
        "```\n",
        "\n",
        "### Benefits\n",
        "- âœ… No API keys, no monthly bills\n",
        "- âœ… No copyright strikes\n",
        "- âœ… 100% monetization-safe\n",
        "- âœ… Variety maintained (25 tracks = 25 different shorts sound unique)\n",
        "- âœ… Works forever (music doesn't change, API doesn't break)\n",
        "\n",
        "---\n",
        "\n",
        "## Verification Checklist Before Upload\n",
        "\n",
        "Before uploading to Drive, verify each track:\n",
        "\n",
        "```\n",
        "âœ“ License: \"Royalty-Free\" or \"Creative Commons 0\" (public domain)\n",
        "âœ— AVOID: \"Creative Commons Attribution\" (requires crediting)\n",
        "âœ— AVOID: \"Creative Commons Share-Alike\"\n",
        "\n",
        "âœ“ Duration: 30-90 seconds (short clips)\n",
        "âœ“ Genre: Upbeat, energetic, modern\n",
        "âœ“ BPM: 90-140 (pairs well with viral pacing)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## File Organization in Drive\n",
        "\n",
        "```\n",
        "MyDrive/\n",
        "â”œâ”€â”€ Shorts_Assets/\n",
        "â”‚   â”œâ”€â”€ Music/\n",
        "â”‚   â”‚   â”œâ”€â”€ track_001.mp3\n",
        "â”‚   â”‚   â”œâ”€â”€ track_002.mp3\n",
        "â”‚   â”‚   â”œâ”€â”€ ...\n",
        "â”‚   â”‚   â””â”€â”€ track_025.mp3\n",
        "â”‚   â””â”€â”€ (Other assets folder)\n",
        "â””â”€â”€ Shorts_Output/\n",
        "    â”œâ”€â”€ short_20260122_001.mp4\n",
        "    â”œâ”€â”€ short_20260122_002.mp4\n",
        "    â””â”€â”€ ...\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Cost Breakdown\n",
        "\n",
        "| Item | Cost | Frequency |\n",
        "|------|------|-----------|\n",
        "| YouTube Audio Library | $0 | One-time setup (1 hour) |\n",
        "| Google Drive Storage | $0 | Free 15GB included |\n",
        "| Google Colab | $0 | Free tier unlimited |\n",
        "| Edge-TTS (voice) | $0 | Microsoft free forever |\n",
        "| FFmpeg | $0 | Open source |\n",
        "| n8n (self-hosted) | $0 | Open source |\n",
        "| **TOTAL MONTHLY COST** | **$0** | **$0** |\n",
        "\n",
        "*Note: If you exceed Google Drive storage (15GB), upgrade to $1.99/100GB*\n",
        "\n",
        "---\n",
        "\n",
        "## Checklist: Setup in 30 Minutes\n",
        "\n",
        "- [ ] Visit YouTube Audio Library\n",
        "- [ ] Download 25 copyright-free tracks\n",
        "- [ ] Create folder: `MyDrive/Shorts_Assets/Music`\n",
        "- [ ] Upload all 25 tracks to that folder\n",
        "- [ ] Run script below to verify folder integrity\n",
        "- [ ] Done! System will randomize music forever\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6bf8eef",
      "metadata": {
        "id": "a6bf8eef"
      },
      "outputs": [],
      "source": [
        "# Music Folder Verification Script\n",
        "\n",
        "def verify_music_folder(music_folder: str = None) -> dict:\n",
        "    \"\"\"\n",
        "    Verify and report on music folder contents.\n",
        "    Run this after uploading tracks to ensure setup is correct.\n",
        "    \"\"\"\n",
        "    if music_folder is None:\n",
        "        music_folder = os.environ['MUSIC_FOLDER']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"MUSIC FOLDER VERIFICATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Check folder exists\n",
        "    if not os.path.exists(music_folder):\n",
        "        print(f\"âœ— ERROR: Folder not found: {music_folder}\")\n",
        "        return {\"status\": \"failed\"}\n",
        "\n",
        "    print(f\"âœ“ Folder found: {music_folder}\\n\")\n",
        "\n",
        "    # List all audio files\n",
        "    audio_extensions = ('.mp3', '.wav', '.m4a', '.aac', '.flac')\n",
        "    music_files = [f for f in os.listdir(music_folder)\n",
        "                   if f.lower().endswith(audio_extensions)]\n",
        "\n",
        "    print(f\"Found {len(music_files)} audio tracks:\\n\")\n",
        "\n",
        "    total_size = 0\n",
        "    for i, filename in enumerate(sorted(music_files), 1):\n",
        "        filepath = os.path.join(music_folder, filename)\n",
        "        size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
        "        total_size += size_mb\n",
        "        print(f\"  {i:2d}. {filename:40s} ({size_mb:6.2f} MB)\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Total Size: {total_size:.2f} MB\")\n",
        "    print(f\"Recommendation: Aim for 20-30 tracks (100-500 MB)\")\n",
        "\n",
        "    if len(music_files) < 5:\n",
        "        print(\"âš ï¸  WARNING: Less than 5 tracks. Add more for variety!\")\n",
        "    elif len(music_files) >= 20:\n",
        "        print(\"âœ“ Excellent: Enough variety for many shorts\")\n",
        "\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"track_count\": len(music_files),\n",
        "        \"total_size_mb\": total_size,\n",
        "        \"tracks\": music_files\n",
        "    }\n",
        "\n",
        "# Run verification\n",
        "music_status = verify_music_folder()\n",
        "\n",
        "# Print recommendations\n",
        "if music_status[\"track_count\"] < 5:\n",
        "    print(\"\\nðŸ“ NEXT STEP: Upload at least 5 music tracks\")\n",
        "    print(\"   1. Go to YouTube Studio > Audio Library\")\n",
        "    print(\"   2. Download 5-25 royalty-free tracks\")\n",
        "    print(\"   3. Upload to:\", os.environ['MUSIC_FOLDER'])\n",
        "else:\n",
        "    print(\"\\nâœ“ Your music library is ready!\")\n",
        "    print(\"   System will randomly select tracks for each short\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}